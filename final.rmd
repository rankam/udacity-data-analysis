---
title: "Final"
output: html_document
---

###Preparations
```{r, message=F, warning=F}
library(ggplot2)
library(arm)
library(cvTools)
library(pROC)
require(coefplot)
library(reshape2)
library(boot)
library(plyr)
library(dplyr)
library(lubridate)
library(glmnet)
library(Hmisc)
library(jsonlite)
library(zoo)
require(scales)
require(stringr)
require(zipcode)
theme_set(theme_minimal(20))
```

###Helper Functions
```{r, message=F, warning=F}
groupData <- function(initial_data,...){
# helper function to make frequent grouping of data with diffrent variables easier
gp_data <-group_by(na.omit(initial_data),...)
gps_data<-summarise(gp_data, 
                  mean_contb = mean(contb_receipt_amt),
                  median_contb = median(contb_receipt_amt),
                  sum_contb = sum(contb_receipt_amt),
                  mean_pop = mean(population),
                  median_pop = median(population),
                  median_elect_delta = median(elect_delta),
                  mean_elect_delta = mean(elect_delta),
                  count = n()) 
gps_data
}

add_city <- function(city){
  # adds binary feature if the contributor's zip code is within a city
  # zip codes are used because I wanted to include the surrounding areas
   sapply(data$contbr_zip, function(zip){
    if (substring(as.character(zip),1,5) %in% city){
      1
    }
    else{
      0
    }
    })
}
```

###Dataset
```{r, message=F, warning=F}

data <- read.csv('~/projects/udacity_DataR/P00000001-OH.csv', sep=',',row.names=NULL,stringsAsFactors = FALSE)
colnames(data)[1:18] <- colnames(data)[2:19] # The dataset had each column name shifted to the right one place with an additional column at the end filled with NAs. 
data <- data[1:18]
dim(data)
names(data)
str(data)
```
The data contains 19 features which makes it difficult to understand. Ideally, I would like to reduce the number of features to no more than 10. However, what I can tell is that the majority of the conbributions were made to Barack Obama (71%) and Mitt Romney (22%) with the other 12 candidates splitting the remaining 7% of contributions. I can also see that the candidate's party is not included the dataset - it will be necessary to add this information as it is vital to answering the question, "to which party did the contributor donate"?
###Add Population of the Contributor's City
```{r, message=F, warning=F}
pops <- fromJSON('~/projects/udacity_DataR/ohio_city_populations.json') # census data
data$population <- sapply(data$contbr_city,function(x) { 
  ifelse(x %in% names(pops),return(pops[as.character(x)]),return(NA))
  }) 
data$population <- as.numeric(data$population) 
```
###Create a Feature Describing how many days from the Election the Contribution was Made
```{r, message=F, warning=F}
data$contb_receipt_dt <- as.Date(data$contb_receipt_dt, "%d-%b-%y")
election_day <- as.Date("2012-11-06")
data$elect_delta <- sapply(data$contb_receipt_dt,function(x) {return(election_day - x)}) # days from general election day
```
###Identify the Party of each Candidate
```{r, message=F, warning=F}
cand_party = list()    
for (cand in unique(data$cand_nm)){
   if(cand == 'Obama, Barack'){
    cand_party['Obama, Barack'] <- 'D'
  }     
  else if(cand == 'Stein, Jill'){
    cand_party['Stein, Jill'] <- 'G'
  } else if(cand == 'Johnson, Gary Earl'){
    cand_party['Johnson, Gary Earl'] <- 'L'
  } else{
    cand_party[as.character(cand)] <- 'R'
  }
}
data$cand_party <- sapply(as.character(data$cand_nm), function(x) {as.character(cand_party[x])})
```

###Additional Cleaning
```{r, message=F, warning=F}
data$contbr_zip <- substr(as.character(data$contbr_zip),1,5)
```
Zip codes should be treated as categorical variables and I want to limit it to the main 5 digit zip code without the additional information
```{r, message=F, warning=F}
data <- subset(data,contb_receipt_amt >0)
```
I'm not concerned with negative donations - I'm not really sure what they mean
```{r, message=F, warning=F}
data <- na.omit(data) 
```
There are 100k+ rows and it's exploratory analysis so I'm going to just going to drop all NAs - if I wanted to publish my analysis or put it into "production", I would revisit the NAs to ensure they were random as opposed to systematic. Though, I guess it could be argued that understanding if NAs are random or systematic could be considered part of EDA. 

###Predicting Gender
```{r, message=F, warning=F}


# Extract first name necessary to predict gender
data$contbr_fnm <- sapply(data$contbr_nm, function(name) {
       f.name <- str_extract(as.character(name),", [[:alpha:]]+($|[[:space:]])")
       f.name <- str_replace(f.name,", ","")
       f.name <- str_trim(f.name)
       return(as.character(f.name))    
  })
write.csv(data,'~/projects/udacity_DataR/data_gender_pred.csv')
```
I need to predict the gender of the contributors that did not include MR., MRS., or MS. I attempted to use the gender package in R, but it was very slow (it never completed the task, but it had been over 8 hours when I finally stopped it). As such, I decided to use Python's NLTK library for the task and created a script called classify_gender.py. Running classify_gender creates a new csv file (data_gender_predicted.csv) with predicted gender names and prints "You classified 0.7704 correct on the test set" to stdout. 

Trying to use all of the information provided in the original file, I wrote a web scraping script, get_estimated_salaries.py, in Python that attempted to get salary information for different occupations. Indeed.com allows you to enter an occupation and zip code and returns an average salary. After running both scripts, I load the results back into R.
```{r, message=F, warning=F}
data <- read.csv('~/projects/udacity_DataR/data_w_salary_gender.csv',stringsAsFactors = FALSE)
# predicted_gender is a better variable name
data$predicted_gender <- data$gender 

# check to see if the contributor identified their gender in their name
data$gender<- sapply(as.character(data$contbr_nm), function(name) {
                  
                  if(grepl("MRS.",name)){
                    return("female")
                  }
                  else if(grepl("MR.",name)){
                      return("male")
                  }
                  else if(grepl(" MS.",name)){
                    return("female")
                  }
                  else{
                    return(as.character(NA))
                  }
                })

# create a feature based on if the contributor included MR. MRS., or MS. in their name
data$included_gender <- ifelse(is.na(data$gender), 0, 1)

# use predicted gender for those contributos that did not include MR., MRS., MS. in their contribution

final_gender <- sapply(1:length(data$gender), function(i){
    if (is.na(data$gender[i])){
      data$predicted_gender[i]  
    }
    else{
    data$gender[i]
    }
   
  })
data$predicted_gender <- final_gender

```




```{r, message=F, warning=F}
# making an assumption that if the contributor's name, city, and employer show up more than once, it is the same person
# this would indicate that they made multiple contributions
rows <- paste(data$contbr_nm, data$contbr_city, data$contbr_employer, sep=" ")
data$multiple_contb <- ifelse(duplicated(rows) == TRUE, 1, 0)

# http://www.city-data.com/ allowed me to search for zipcodes in specific cities
cbus <- as.character(c(43002, 43004, 43016, 43017, 43026, 43035, 43054, 43065, 43081, 43082, 43085, 43119, 43123, 43137, 43147, 43201, 43202, 43203, 43204, 43205, 43206, 43207, 43210, 43211, 43212, 43213, 43214, 43215, 43217, 43219, 43220, 43221, 43222, 43223, 43224, 43227, 43228, 43229, 43230, 43231, 43235, 43240))
cleveland <- as.character(c(44101, 44103, 44104, 44105, 44106, 44107, 44111, 44112, 44113, 44114, 44115, 44117, 44119, 44120, 44121, 44125, 44127, 44134))
cincy <- as.character(c(45202, 45203, 45204, 45205, 45206, 45207, 45208, 45209, 45212, 45214, 45216, 45217, 45219, 45220, 45223, 45224, 45225, 45226, 45227, 45229, 45230, 45231, 45232, 45239, 45243))
data$cincy <- add_city(cincy)
data$cbus <- add_city(cbus)
data$cleveland <- add_city(cleveland)

# drop rows without an estimated salary
data <- subset(data, estimated_salary!= 'No Data ') 

# estimated salary was a string
data$estimated_salary <- as.numeric(data$estimated_salary)
```


# Single Variable

# Features Contained in Original Dataset

# Contribution Amount
```{r, echo=FALSE}
ggplot(aes(data$contb_receipt_amt), data=data) + geom_density() + xlim(-100,1000)
ggplot(aes(log(data$contb_receipt_amt)), data=data) + geom_density()
```
The contribution amount is not normally distributed and is multi-modal. It appears that the most frequent contribution amounts were less than or equal to $100 with a $100 donation being the most frequent. One can also see that the data contains peaks at specific values such as 100, 250, 500, 1,000 - I can infer that this is a result of campaigns explicity asking for specific amounts (e.g. they ask for donations of $500, $1000, $1500 but do not ask for $400 or $900). 



# Election Type
```{r, echo=FALSE}
table(data$election_tp)
ggplot(data,aes(election_tp)) + geom_bar()
```
election_tp tells in which election the donation was made; namely the Primary or General Election which respectively accounted for 45% and 55% of all donations.

# Contributor's Occupation
```{r, echo=FALSE}
describe(data$contbr_occupation)
```
There are over 6,000 unique occupations - far too many visually look at. 

# Contributor's Employer
```{r, echo=FALSE}
describe(data$contbr_employer)
```
There are over 11,000 unique employers - far too many visually look at. 

# Contributor's City
```{r, echo=FALSE}
describe(data$contbr_city)
```


# Contributor's Zip Code
```{r, echo=FALSE}
describe(data$contbr_zip)
```

# Contributor's Name
```{r, echo=FALSE}
describe(data$contbr_nm)
```



# Newly Created Features

# Population of Contributor's City
```{r, echo=FALSE}
ggplot(aes(data$population), data=data) + geom_density() + scale_x_continuous(labels = comma) 
ggplot(aes(log(population + 1)), data=data) + geom_density() + scale_x_continuous(labels = comma) 
summary(data$population)
```
The population data is multi-modal. The majority of contributors live in a city with a population less than 100,000. 

# Number of Days from the General Election the Contribution was Made
```{r, echo=FALSE}
qplot(data$elect_delta)
```

elect_delta follows the log-normal distribution. This makes sense as American's are typically apathetic towards politics especially when an election is months or years away. The two campaigns were also likely to  have ramped up their efforts to solicit contributions as election day neared. 

# Candidate's Party
```{r, echo=FALSE}
ggplot(data, aes(cand_party)) + geom_bar()
describe(data$cand_party)
```

# Gender of Contributor
```{r, echo=FALSE}
table(data$gender)
```
# Contributor Included their Gender when Contributing
```{r, echo=FALSE}
table(data[c('included_gender', cand_party)])
```

Out of the ~19,000 records where the contributor provided an indication of their gender by using "MS.", "MRS.", or "MR." and where the contribution amount was greater than 0, only 138 contributed to Democratic campaigns. Of these 138, 2 used "MRS." or "MS." and 136 used "MR.". Using the way back machine, I looked at the Obama and Romney donation page on their website - neither seemed to ask for gender nor have a form for the donor to include their salutation. It could be that Democrats are less likely to associate or define themselves by gender or that younger people are less likely to do this (Democrats tend to be younger than Republicans). Regardless of the reason, creating a feature out of this information could be useful in predicting in which party the donor made their contribution. 

# Contributor's Estimated Salary
```{r, echo=FALSE}
qplot(data$estimated_salary, geom='density')
qplot(log(data$estimated_salary + 1), geom='density')
```
# Multiple Contributions
```{r, echo=FALSE}
table(data$multiple_contb)
```

###Variables to be Dropped
RECEIPT_DESC
MEMO_CD
MEMO_TEXT
FORM_TP
FILE_NUM
TRAN_ID
This information, while related to the donation, was reported by the committee about a specific contribution and is not included by the donor. Because of this, I will drop it from the dataset.
See http://webcache.googleusercontent.com/search?q=cache:eE9YB7REtkEJ:ftp://ftp.fec.gov/FEC/Presidential_Map/2012/DATA_DICTIONARIES/CONTRIBUTOR_FORMAT.txt+&cd=2&hl=en&ct=clnk&gl=us for further information regarding variables.


```{r, message=F, warning=F}
data.party <- groupData(data, cand_party)
ggplot(aes(x=cand_party,y=mean_contb), data=data.party) + geom_bar(stat='identity')
ggplot(aes(x=cand_party,y=median_contb), data=data.party) + geom_bar(stat='identity')
ggplot(data,aes(data$elect_delta, color=data$cand_party)) + geom_density() 
ggplot(data,aes(log(elect_delta +1), color=cand_party)) + geom_density() 

ggplot(aes(x=log(contb_receipt_amt +1)), data=data) + geom_density(aes(color=cand_party))

ggplot(aes(x=cand_party,y=count), data=data.party) + geom_bar(stat='identity')

ggplot(aes(x=cand_party,y=median_pop), data=data.party) + geom_bar(stat='identity')

ggplot(aes(y=log(contb_receipt_amt),x=1), data=data) + geom_boxplot(aes(fill=cand_party))
```

Democrats received a greater number of contributions in small amounts while Republicans received higher contribution amounts from fewer contributors.

```{r, message=F, warning=F}
data(zipcode)
data$zip <- clean.zipcodes(data$contbr_zip)
oh <- subset(zipcode, state=='OH') # zipcode package would change my zipcode in 'data' variable to zip codes in MA for some reason. Subsetting only Ohio values from zipcode seemed to solve this issue
map.data <- merge(subset(data, contb_receipt_amt > 0), oh, by.x='contbr_zip', by.y='zip')

map.plot <- ggplot(data=subset(map.data,cand_party == 'D' | cand_party == 'R'),aes(x=longitude, y=latitude, color=cand_party, size = contb_receipt_amt)) + geom_point(position = position_jitter(w=.08,h=.08)) + scale_size_continuous(breaks = c(50,100,500,1000,2500,5000,10000),range=c(1,15)) + labs(x=NULL, y=NULL)
map.plot <- map.plot + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.ticks=element_blank(),axis.text.x=element_blank(),axis.text.y=element_blank())
map.plot
```

The map makes it easy to spot the most populated cities in Ohio. The center mass is Columbus and to its left, you can see a cluster which contains Dayton at the top and Cincinatti at the bottom. The top right cluster is the Cleveland area and the top left is Toledo. The size of each point indicates the amount of the contribution. Contributions to Republicans appear to be larger than contributions to Democrats. However, there are more contributions made to Democrats than Republicans. 

# Predicting to which Party the Contribution was Made via Logistic Regression

Because I am trying to classify if the contributor donated to a Democrat or Republican, logistic regression is an appropriate model with which to start. Logistic regression uses a a set of covariates to predict
probabilities of (binary) class membership. We can then set a threshold to map these probabilities to class labels to solve the classification problem. Any probablity 0.50 and above indicates that the contributor is more likely to have donated to a Democrat while an output below 0.50 indicates that the contributor was more likely to have donated to a Republican.

### Logistic Regression in Detail
Logistic regression is an extension of the linear regression model with two important differences:
 - the outcome variable
 - the error term
####Outcome Variable
Key to any regression problem is the conditional mean of the outcome variable y given x. In linear regression, we assume that the conditional mean is a linear function taking values in $(-\infty, \infty)$:
$${E(y|x) =}\; \alpha + \beta{x}$$
Unlike linear regression, the outcome variable of logistic regression has a conditional mean that takes values within [0,1]. In order to extend the linear regression model to logistic regression, we must map the outcome variable $E(y|x)$ into [0,1] via a transformation called the logistic function. 
$${E(y|x) =}\;\pi(x) = {e^\alpha+\beta{x}\over 1 + e^{\alpha+\beta{x}}}$$
The logit function or log-odds function is a transformation of the logistic function. It can be useful in helping interpret the results.
$${g(x)=}\; \ln({\pi(x)\over {1-\pi(x)}}) = \alpha + \beta{x}$$

####Error Terms
One of the key assumptions of linear regression is that the error terms
follow independent Gaussian distributions with zero mean and
constant variance.

In logistic regression, the outcome variable can only be 0 or 1. Because of this, we can see that the error terms of logistic regression follow a Bernoulli distribution:
$$\epsilon \sim \beta(0,\pi(1 - \pi))$$

####Interpreting Results
In linear regression, the parameter $\beta$ represents the change in the
response variable for a unit change in the covariate.
In logistic regression, $\beta$ represents the change in the logit function for a unit change in the covariate. To interpret this change, we must define odds ratio. 

The odds ratio of a binary event is given by the odds of the event divided by the odds of its complement: 
$${OR =}\; {O(x=1)\over{O(x=0)}} = {\pi(i)/(1-\pi(1))\over{\pi(i)/(0-\pi(0))}}$$

Substituting the definition of $\pi(x)\$ into this equation yields
$${OR = }\; \epsilon^\beta$$
The relationship between the odds ratio and $\beta$ is what makes logistic regression such a powerful tool. 

```{r, message=F, warning=F}
# prepare the data set
glm.data <- data[c(11, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 33)]
# this is America, third parties get ignored
glm.data <- subset(glm.data, cand_party == 'D' | cand_party == 'R') 
glm.data <- na.omit(glm.data)
glm.data$cand_party <- ifelse(glm.data$cand_party == 'D', 1, 0)
glm.data$predicted_gender <- ifelse(glm.data$predicted_gender == 'male',1,0)
glm.data$election_tp <- ifelse(glm.data$election_tp == 'G2012',1,0)


smp_size <- floor(0.75 * nrow(glm.data))
## set the seed to make your partition reproductible
set.seed(1)
train_ind <- sample(seq_len(nrow(glm.data)), size = smp_size)
train <- glm.data[train_ind, ]
test <- glm.data[-train_ind, ]

fit <- glm(cand_party ~ log(contb_receipt_amt + 1) + log(estimated_salary+1) + predicted_gender   + cbus + cincy + cleveland   + log(elect_delta + 1) + election_tp +  log(population+1) + multiple_contb + included_gender, data=train, family="binomial")
predpr <- predict(fit, newdata=test,type="response")
test$predicted <- predpr
coefplot(fit,intercept=FALSE)
```
###Evaluating Performance
There are different ways to evaluate the performance a logistic regression model. I chose to use two techniques, the receiver operating characterstic (ROC) curve and cross-validation. 

####ROC Curve
A ROC curve is a graphical illustration of the performance of a binary classification system that plots the Sensitivity against the Specificity.
 - Sensitivity $P(\hat{Y}_i=1 | Y_i=1)$ the proportion of 1s (Democrats, in our case) that are correctly identified or Does the model do a good job of detecting those contributions made to Democrats
 - Specificity $P(\hat{Y}_i=0 | Y_i=0)$ the proportion of 0s (Republicans) that are correctly identified or Does the model do a good job of detecting those contributions that are not made to Democrats
 
Our logistic regression model is not predicting if the contribution was made to Democrats or if the contribution was made to Republicans. Instead, it is only predicting if the contribution was made to Democrats. If the model predicts that the contribution was not made to Democrats, then the prediction will be the other choice which is Republicans in our case. (http://stats.stackexchange.com/questions/49469/how-do-i-compute-a-cutoff-based-on-sensitivity-specificity-when-the-characterist)
While it is possible to provide specific details about the truth and false positive rates, it should suffice to say that we can think of the truth positive rate as correctly classified and the false positive rate as incorrectly classified. Plotting the true positive rate against the false positive rate will show the ROC curve and by calculating the area under this curve (AUC), we are able to evaluate the performance of our model. The more area under the ROC curve indicates greater predictive power: 
 - auc of 0.5 = no predictive power
 - auc of 1.0 = perfect predictive power 

```{r, message=F, warning=F}
glm.roc <- roc(test$cand_party ~ predpr)
plot(glm.roc)
auc <- round(glm.roc$auc,2)
roc.df <- data.frame(specificities=glm.roc$specificities,sensitivities = glm.roc$sensitivities)

ggplot(roc.df,aes(1-specificities, sensitivities)) + geom_line(aes(), size=1.5) + geom_abline(intercept = 0) + xlab('1 - Specificity (False Positive Rate)') + ylab('Sensitivity (True Positive Rate)') + annotate("text",x=.7,y=0.95,label=paste('The Area Under the Curve is',auc))
```

####Cross-validation
```{r, message=F, warning=F}
cv.fit <- cv.glm(train, fit, K=10)
cv.error <- cv.fit$delta
```

The second method I will use to evaluate my model is cross-validation, specifically a K-Fold Cross-Validation. Cross-validation involves the following steps: 
 - Randomly split the dataset into n equal partitions.
 - Use partition 1 as test set & union of other partitions as training set.
 - Find generalization error.
 -Repeat steps 2-3 using a different partition as the test set at each iteration.
 - Take the average generalization error as the estimate of out-of-sample accuracy. 

```{r, message=F, warning=F}
# Code inspired by Machine Learning for Hackers by Drew Conway and John Myles White
set.seed(1)
glm.data <- data[c(11, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 33)]
glm.data <- subset(glm.data, cand_party == 'D' | cand_party == 'R') # this is America, third parties get ignored
glm.data <- na.omit(glm.data)
glm.data$cand_party <- ifelse(glm.data$cand_party == 'D', 1, 0)
glm.data$predicted_gender <- ifelse(glm.data$predicted_gender == 'male',1,0)
glm.data$election_tp <- ifelse(glm.data$election_tp == 'G2012',1,0)

performance <- data.frame()

for (i in 1:10)
{
  smp_size <- floor(0.75 * nrow(glm.data))
  indices <- sample(seq_len(nrow(glm.data)), size = smp_size)
  training.x <- as.matrix(glm.data[indices,c(1:4,6:12) ])
  training.y <- as.matrix(glm.data[indices,c(5)])
  
  test.x <- as.matrix(glm.data[-indices,c(1:4,6:12)  ])
  test.y <- as.matrix(glm.data[-indices,c(5)])

  for (lambda in c(0.00001, 0.0001, 0.001, 0.01))
  {
    glm.fit <- glmnet(training.x, training.y, family = 'binomial')
    predicted.y <- ifelse(predict(glm.fit, test.x, s = lambda) > 0, 1, 0)
    error.rate <- mean(predicted.y != test.y)

    performance <- rbind(performance,
                         data.frame(Lambda = lambda,
                                    Iteration = i,
                                    ErrorRate = error.rate))
  }
}

ggplot(performance, aes(x = Lambda, y = ErrorRate)) +
    stat_summary(fun.data = 'mean_cl_boot', geom = 'errorbar') +
    stat_summary(fun.data = 'mean_cl_boot', geom = 'point') +
    scale_x_log10()

plot(cv.glmnet(training.x, training.y, family="binomial", type.measure='auc'))
```
